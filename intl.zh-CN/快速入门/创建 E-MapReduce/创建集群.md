# 创建集群 {#concept_nrp_154_y2b .concept}

## 进入创建集群页面 {#section_w2j_2z4_y2b .section}

1.  登录[阿里云 E-MapReduce 控制台](https://emr.console.aliyun.com/)。
2.  完成 RAM 授权，操作步骤请参见[角色授权](../../../../intl.zh-CN/用户指南/角色授权.md#)。
3.  在上方选择所在的地域（Region），所创建集群将会在对应的地域内，一旦创建后不能修改。
4.  单击**创建集群**，进行创建。

## 创建集群流程 {#section_rsk_gz4_y2b .section}

要创建集群，您需要继续完成以下三个步骤：

-   软件配置
-   硬件配置
-   基础配置

步骤1：软件配置

配置项说明：

-   **产品版本**：选择默认最新的软件版本。
-   **集群类型**：目前的EMR提供了。
    -   Hadoop集群，提供半托管的Hadoop、Hive、Spark离线大规模分布式数据存储和计算，SparkStreaming、Flink、Storm流式数据计算，Presto、Impala交互式查询，Oozie、Pig等Hadoop生态圈的组件，具体的组件信息可以在选择界面的列表中查看。
    -   Kafka集群，是半托管布式的、高吞吐量、高可扩展性的消息系统。提供一套完整的服务监控体系，保障集群稳定运行，用户无需部署运维，更专业、更可靠、更安全。广泛用于日志收集、监控数据聚合等场景，支持离线或流式数据处理、实时数据分析等。
    -   Druid集群，提供半托管式实时交互式分析服务，大数据查询毫秒级延迟，支持多种数据摄入方式。可与 EMR Hadoop、EMR Spark、OSS、RDS 等服务搭配组合使用，构建灵活稳健的实时查询解决方案。
    -   Data Science集群，主要面向大数据+AI场景，提供了Hive、Spark离线大数据ETL，TensorFlow模型训练，用户可以选择CPU+GPU的异构计算框架，利用英伟达GPU对部分深度学习算法就行高性能计算。
-   **包含配置**：使用默认的配置，后期可以在管理界面中添加和启停服务。
-   **安全模式**：是否开启集群的 Kerberos 认证功能。一般的个人用户集群无需该功能，默认关闭它。
-   **软件自定义配置**：可以指定一个json文件修改软件配置，详细使用方法请参见[软件配置](../../../../intl.zh-CN/用户指南/软件配置.md#)。

步骤2：硬件配置

配置项说明：

-   付费配置

    -   **付费类型**：测试的场景下使用按量开始，测试都正常了以后。可以新建一个包月的生产集群正式使用。
-   集群网络配置
    -   **集群可用区**：一般使用默认的可用区即可。
    -   **网络类型**：默认使用VPC。若还未创建，可前往[VPC控制台](https://vpc.console.aliyun.com/)进行创建。
    -   **可用区:**：可用区为在同一地域下的不同物理区域，可用区之间内网互通。
    -   **VPC**：选择在该地域的VPC。如没有，单击**创建 VPC / 子网\(交换机）**前往新建。
    -   **交换机**：选择在对应的VPC下的在对应可用区的交换机，如果在这个可用区没有可用的交换机，那么就需要前往去创建一个新的使用。
    -   **安全组**：一般用户初次来到这里还没有安全组，用户可以输入新的安全组名称新建一个安全组。若已经有在使用的安全组可以直接这里选择使用。
-   集群节点配置
    -   **高可用**：打开后，Hadoop集群会有2个master来支持Resource Manager和Name Node的高可用。HBase集群原来就支持高可用，只是另一个节点用其中一个core节点来充当，如果打开高可用，会独立使用一个master节点来支持高可用，更加的安全可靠。后续正式集群如果是使用高可用的，测试情况下也打开高可用。
    -   Master节点：主要负责Resource Manager，Name node等控制进程的部署。
        -   **Master配置**：根据需要选择实例规格，请参考[实例规格族](../../../../intl.zh-CN/产品简介/实例规格族.md#)。
        -   **系统盘配置**：根据需要选择高效或者是SSD云盘。
        -   **系统盘大小**： 根据需要调整磁盘容量，推荐至少120G。
        -   **数据盘配置**：根据需要选择高效或者是SSD云盘。
        -   **数据盘大小**：根据需要调整磁盘容量，推荐至少80G。
        -   **Master数量**：默认1台。
    -   Core节点：主要负责集群所有数据的存储，可以按照需要进行扩容。
        -   **Core配置**：根据需要选择实例规格，请参考[实例规格族](../../../../intl.zh-CN/产品简介/实例规格族.md#)。
        -   **系统盘配置**：根据需要选择高效或者是SSD云盘。
        -   **系统盘大小**： 根据需要调整磁盘容量，推荐至少80G。
        -   **数据盘配置**：根据需要选择高效或者是SSD云盘。
        -   **数据盘大小**：根据需要调整磁盘容量，推荐至少80G。
        -   **Core数量**：默认2台，根据需要调整。
    -   **任务实例组**：不保存数据，调整集群的计算力使用。默认关闭，需要的时候再追加。

步骤3：基础配置

配置项说明：

-   **基础信息**

    -   **集群名称**：集群的名字，长度限制为 1-64 个字符，仅可使用中文、字母、数字、中划线（-）和下划线（\_）。
-   **运行日志**

    -   **运行日志**：是否保存作业的日志，日志保存默认是打开的。开启后会需要您选择用来保存日志的 OSS 目录位置，会将您的作业的日志保存到该 OSS 存储目录上。当然，您要使用这个功能必须先开通 OSS，同时上传的文件会按照使用的量来计算用户的费用。强烈建议您打开 OSS 日志保存功能，这会对您的作业调试和错误排查有极大的帮助。
    -   **日志路径**：保存日志的 OSS 路径。
    -   **统一Meta数据库**：Hive使用统一的集群外部的meta数据库，集群释放后meta信息仍然存在。推荐先关闭。
-   **权限设置**：无需调整，使用默认即可。
-   **登录设置**
    -   **远程登录**：是否打开安全组22端口，默认开启。
    -   **登录密码**：设置 master 节点的登录密码。8 - 30 个字符，且必须同时包含大写字母、小写字母、数字和特殊字符!@\#$%^&\*。
-   **引导操作**（可选）： 您可以在集群启动 Hadoop 前执行您自定义的脚本，详细使用说明请参见。

## 配置清单和集群费用 {#section_gtk_gz4_y2b .section}

在配置清单上确认配置和对应的费用。

## 确认创建 {#section_htk_gz4_y2b .section}

当所有的信息都有效填写以后，**创建**按钮会亮起，确认无误后单击**创建**将会创建集群。

**说明：** 

-   若是按量付费集群，集群会立刻开始创建。页面会返回集群列表页，就能看到在**集群概览**中有一个**初始化中**的集群。请耐心等待，集群创建会需要几分钟时间。完成之后集群的状态会切换为**空闲**。
-   若是包年包月集群，则会先生成订单，在支付完成订单以后集群才会开始创建。

## 创建失败 {#section_jtk_gz4_y2b .section}

如果创建失败，在集群列表页上会显示**集群创建失败**，将鼠标移动到红色的感叹号上会看到失败原因，如下图所示。

创建失败的集群可以不用处理，对应的计算资源并没有真正的创建出来。这个集群会在停留3天以后自动隐藏。

