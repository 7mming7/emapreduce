# E-MapReduce 快速开始 {#concept_jkh_sb4_y2b .concept}

**说明：** 请确认您已经完成了**必选**的[准备工作](intl.zh-CN/快速入门/准备工作.md#)。

通过本教程，用户能够基本了解E-MapReduce中集群、作业和执行计划的作用和使用方法。能够创建一个Spark Pi的作业在集群上运行成功，并最后在控制台页面上看到圆周率Pi的近似计算结果。

1.  创建集群。
    1.  在[EMR产品控制台](https://emr.console.aliyun.com/)左侧选择**集群**，并单击右上**创建集群**。
    2.  软件配置。
        1.  选择最新的EMR产品版本，比如**EMR-3.4.1**。
        2.  使用默认软件配置。
    3.  硬件配置
        1.  选择**按量付费**。
        2.  若没有安全组，打开**新建**，并填写安全组名称。
        3.  选择 Master 4核8G。
        4.  选择 Core 4核8G， 两台。
        5.  其他保持默认。
    4.  基础配置。
        1.  填写集群名称。
        2.  选择日志路径保存作业日志，**务必开启**。**在集群对应的地域**，[创建OSS的Bucket](https://oss.console.aliyun.com/#/)。
        3.  填写密码。
    5.  创建集群。
2.  创建作业。
    1.  在控制台左侧选择**作业**，并单击右上**创建作业**。
    2.  填写作业名称。
    3.  选择Spark类型。
    4.  参数填写，使用如下。

        ```
        --class org.apache.spark.examples.SparkPi --master yarn-client --driver-memory 512m --num-executors 1 --executor-memory 1g --executor-cores 2 /usr/lib/spark-current/examples/jars/spark-examples_2.11-2.1.1.jar 10
        ```

        **说明：** 这个`/usr/lib/spark-current/examples/jars/spark-examples_2.11-2.1.1.jar`, 需要根据实际集群中的 Spark 版本来修改这个jar包，比如 Spark 是2.1.1的， 那么就是`spark-examples_2.11-2.1.1.jar`,如果是2.2.0的，那么就是`spark-examples_2.11-2.2.0.jar`。

    5.  其他保持默认，创建作业。
3.  创建执行计划。
    1.  确认之前创建的集群已经创建成功以后，在列表上的状态显示为**空闲**。
    2.  在控制台左侧选择**执行计划**，并单击右上**创建执行计划**。
    3.  创建时选择**已有集群**，并选择之前创建集群进行关联。
    4.  将之前创建的作业，加入到运行队列中。
    5.  填写执行计划名称。
    6.  默认**手动执行**。
    7.  创建执行计划。
4.  运行执行计划。
    1.  在执行计划列表页面，单击**立即运行**。
5.  查看作业日志并确认结果。
    1.  单击**管理**，进入管理页面，在下方查看**运行记录**。
    2.  单击运行记录的右侧，查看作业列表。
    3.  单击**stdout**能够查看到Pi的近似计算结果：3.14xxxx。

