# 参数说明 {#concept_sf4_nzg_hfb .concept}

Spark 代码中参数说明

Spark 代码中可使用如下参数配置：

|属性名|默认值|说明|
|---|---|--|
|spark.hadoop.fs.oss.accessKeyId|无|访问 OSS 所需的 AccessKey ID（可选）|
|spark.hadoop.fs.oss.accessKeySecret|无|访问 OSS 所需的 AccessKey Secret（可选）|
|spark.hadoop.fs.oss.securityToken|无|访问 OSS 所需的 STS token（可选）|
|spark.hadoop.fs.oss.endpoint|无|访问 OSS 的 endpoint（可选）|
|spark.hadoop.fs.oss.multipart.thread.number|5|并发进行 OSS 的 upload part copy 的并发度|
|spark.hadoop.fs.oss.copy.simple.max.byte|134217728|使用普通接口进行 OSS 内部 copy 的文件大小上限|
|spark.hadoop.fs.oss.multipart.split.max.byte|67108864|使用普通接口进行 OSS 内部 copy 的文件分片大小上限|
|spark.hadoop.fs.oss.multipart.split.number|5|使用普通接口进行 OSS 内部 copy 的文件分片数目，默认和拷贝并发数目保持一致|
|spark.hadoop.fs.oss.impl|com.aliyun.fs.oss.nat.NativeOssFileSystem|OSS 文件系统实现类|
|spark.hadoop.fs.oss.buffer.dirs|/mnt/disk1,/mnt/disk2,…|OSS 本地临时文件目录，默认使用集群的数据盘|
|spark.hadoop.fs.oss.buffer.dirs.exists|false|是否确保 OSS 临时目录已经存在|
|spark.hadoop.fs.oss.client.connection.timeout|50000|OSS Client 端的连接超时时间（单位毫秒）|
|spark.hadoop.fs.oss.client.socket.timeout|50000|OSS Client 端的 socket 超时时间（单位毫秒）|
|spark.hadoop.fs.oss.client.connection.ttl|-1|连接存活时间|
|spark.hadoop.fs.oss.connection.max|1024|最大连接数目|
|spark.hadoop.job.runlocal|false|当数据源是 OSS 时，如果需要本地调试运行 Spark 代码，需要设置此项为“true”，否则为“false”|
|spark.logservice.fetch.interval.millis|200|Receiver 向 LogHub 取数据的时间间隔|
|spark.logservice.fetch.inOrder|true|是否有序消费分裂后的 Shard 数据|
|spark.logservice.heartbeat.interval.millis|30000|消费进程的心跳保持间隔|
|spark.mns.batchMsg.size|16|批量拉取 MNS 消息条数，最大不能超过 16|
|spark.mns.pollingWait.seconds|30|MNS 队列为空时的拉取等待间隔|
|spark.hadoop.io.compression.codec.snappy.native|false|标识 Snappy 文件是否为标准 Snappy 文件，Hadoop 默认识别的是 Hadoop 修改过的 Snappy 格式文件|

