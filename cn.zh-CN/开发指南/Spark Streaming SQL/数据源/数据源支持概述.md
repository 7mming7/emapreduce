# 数据源支持概述 {#concept_1181189 .concept}

本节简要介绍Spark SQL支持哪些类型的数据源，以及支持数据源的方式。

## 支持的数据源 {#section_fr8_vkw_nda .section}

|数据源|建表带 Schema|建表不带 Schema|读|写|
|---|----------|-----------|--|--|
|Kafka|✅|✅|✅|✅|
|Loghub|✅| |✅|✅|
|TableStore| |✅| |✅|
|HBase| |✅| |✅|
|JDBC| |✅| |✅|
|Druid| |✅| |✅|

## 支持数据源的方式 {#section_tlk_iic_ky4 .section}

Spark SQL支持数据源的方式包括命令行方式和工作流方式两种。

命令行方式

-   下载预编译好的[数据源JAR包](https://github.com/aliyun/aliyun-emapreduce-sdk/blob/master-2.x/jars/datasources/emr-datasources_shaded_2.11-1.7.0.jar)。

    JAR包中包含Loghub、TableStore、HBase和JDBC数据源的实现以及相关依赖包，这几种数据源只需要使用这一个JAR包即可。Kafka和Druid数据源暂未在此JAR包中发布，后续会陆续加入，敬请期待。

-   通过streaming-sql命令行进行交互式开发。

    ``` {#codeblock_fja_z0g_op9}
    [hadoop@emr-header-1 ~]# streaming-sql --master yarn-client --jars emr-datasources_shaded_2.11-${version}.jar --driver-class-path emr-datasources_shaded_2.11-${version}.jar
    ```

-   您也可以使用-f或者-e参数来提交您的SQL语句。
-   如果需要以不退出的方式长时间执行流式作业，您可通过nohup命令使程序以忽略挂起信号的方式来运行。

工作流方式

E-MapReduce将很快在工作流中支持流式SQL作业，敬请期待。

