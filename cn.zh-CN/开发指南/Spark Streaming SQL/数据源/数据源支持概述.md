# 数据源支持概述 {#concept_1181189 .concept}

本节简要介绍Spark SQL支持哪些类型的数据源，以及支持数据源的方式。

## 支持的数据源 {#section_fr8_vkw_nda .section}

|数据源|建表带 Schema|建表不带 Schema|读|写|
|---|----------|-----------|--|--|
|Kafka|✅|✅|✅|✅|
|Loghub|✅|无|✅|✅|
|TableStore|无|✅|无|✅|
|HBase|无|✅|无|✅|
|JDBC|无|✅|无|✅|
|Druid|无|✅|无|✅|
|Redis|无|✅|无|✅|

## 支持数据源的方式 {#section_tlk_iic_ky4 .section}

Spark SQL支持数据源的方式包括命令行方式和工作流方式两种。

-   命令行方式

    -   下载预编译好的[数据源JAR包](https://github.com/aliyun/aliyun-emapreduce-sdk/tree/master-2.x/jars/datasources/latest)。

        JAR包中包含Loghub、TableStore、HBase、JDBC和Redis数据源的实现以及相关依赖包，这几种数据源只需要使用这一个JAR包即可。Kafka和Druid数据源暂未在此JAR包中发布，后续会陆续加入，具体请参见[Release Notes](https://github.com/aliyun/aliyun-emapreduce-sdk/releases)。

    -   通过streaming-sql命令行进行交互式开发。

        ``` {#codeblock_189_dz3_b9c}
        [hadoop@emr-header-1 ~]# streaming-sql --master yarn-client --jars emr-datasources_shaded_2.11-${version}.jar --driver-class-path emr-datasources_shaded_2.11-${version}.jar
        ```

    -   您也可以使用-f或者-e参数来提交您的SQL语句。
    -   如果需要以不退出的方式长时间执行流式作业，您可通过nohup命令使程序以忽略挂起信号的方式来运行。
-   工作流方式

    具体请参见[Streaming SQL作业配置](https://help.aliyun.com/document_detail/130938.html?spm=a2c4g.11186623.6.650.75193d65uhcCkf)。


