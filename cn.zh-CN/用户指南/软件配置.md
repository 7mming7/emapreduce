# 软件配置 {#concept_ctp_kkn_y2b .concept}

Hadoop、Hive、Pig 等软件含有大量的配置，当需要对其软件配置进行修改时，就可以使用软件配置功能来实现。例如，HDFS 服务器的服务线程数目 dfs.namenode.handler.count 默认是 10，假设要加大到 50；HDFS 的文件块的大小 dfs.blocksize 默认是 128MB，假设系统都是小文件，想要改小到 64MB。

## 软件配置的作用 {#section_bd3_ds5_y2b .section}

目前软件配置操作只能在集群启动的时候执行一次。

## 操作步骤 {#section_tsc_2s5_y2b .section}

1.  登录[阿里云 E-MapReduce 控制台集群列表](https://emr.console.aliyun.com/)。
2.  在上方选择所在的地域（Region），所创建集群将会在对应的Region内。
3.  单击**创建集群**，即会进入创建集群的操作界面。
4.  在创建集群的软件配置这一步中可以看到所有包含的软件以及对应的版本。若想修改集群的配置，可以通过软件配置（可选）框选择相应的 json 格式配置文件，对集群的默认参数进行覆盖或添加。json 文件的样例内容如下：

    ```
    {
     "configurations": [
         {
             "classification": "core-site",
             "properties": {
                 "fs.trash.interval": "61"
             }
         },
         {
             "classification": "hadoop-log4j",
             "properties": {
                 "hadoop.log.file": "hadoop1.log",
                 "hadoop.root.logger": "INFO",
                 "a.b.c": "ABC"
             }
         },
         {
             "classification": "hdfs-site",
             "properties": {
                 "dfs.namenode.handler.count": "12"
             }
         },
         {
             "classification": "mapred-site",
             "properties": {
                 "mapreduce.task.io.sort.mb": "201"
             }
         },
         {
             "classification": "yarn-site",
             "properties": {
                 "hadoop.security.groups.cache.secs": "251",
                 "yarn.nodemanager.remote-app-log-dir": "/tmp/logs1"
             }
         },
         {
             "classification": "httpsfs-site",
             "properties": {
                 "a.b.c.d": "200"
             }
         },
         {
             "classification": "capacity-scheduler",
             "properties": {
                 "yarn.scheduler.capacity.maximum-am-resource-percent": "0.2"
             }
         },
         {
             "classification": "hadoop-env",
             "properties": {
                 "BC":"CD"
             },
             "configurations":[
                 {
                     "classification":"export",
                     "properties": {
                         "AB":"${BC}",
                         "HADOOP_CLIENT_OPTS":"\"-Xmx512m -Xms512m $HADOOP_CLIENT_OPTS\""
                     }
                 }
             ]
         },
         {
             "classification": "httpfs-env",
             "properties": {
             },
             "configurations":[
                 {
                     "classification":"export",
                     "properties": {
                         "HTTPFS_SSL_KEYSTORE_PASS":"passwd"
                     }
                 }
             ]
         },
         {
             "classification": "mapred-env",
             "properties": {
             },
             "configurations":[
                 {
                     "classification":"export",
                     "properties": {
                         "HADOOP_JOB_HISTORYSERVER_HEAPSIZE":"1001"
                     }
                 }
             ]
         },
         {
             "classification": "yarn-env",
             "properties": {
             },
             "configurations":[
                 {
                     "classification":"export",
                     "properties": {
                         "HADOOP_YARN_USER":"${HADOOP_YARN_USER:-yarn1}"
                     }
                 }
             ]
         },
         {
             "classification": "pig",
             "properties": {
                 "pig.tez.auto.parallelism": "false"
             }
         },
         {
             "classification": "pig-log4j",
             "properties": {
                 "log4j.logger.org.apache.pig": "error, A"
             }
         },
         {
             "classification": "hive-env",
             "properties": {
                 "BC":"CD"
             },
             "configurations":[
                 {
                     "classification":"export",
                     "properties": {
                         "AB":"${BC}",
                         "HADOOP_CLIENT_OPTS1":"\"-Xmx512m -Xms512m $HADOOP_CLIENT_OPTS1\""
                     }
                 }
             ]
         },
         {
             "classification": "hive-site",
             "properties": {
                 "hive.tez.java.opts": "-Xmx3900m"
             }
         },
         {
             "classification": "hive-exec-log4j",
             "properties": {
                 "log4j.logger.org.apache.zookeeper.ClientCnxnSocketNIO": "INFO,FA"
             }
         },
         {
             "classification": "hive-log4j",
             "properties": {
                 "log4j.logger.org.apache.zookeeper.server.NIOServerCnxn": "INFO,DRFA"
             }
         }
     ]
    }
    ```


classification 参数指定要修改的配置文件，properties 参数放置要修改的 key value 键值对，默认配置文件有对应的 key 有则只覆盖 value，没有则添加对应的 key value 键值对。

配置文件与 classification 的对应关系如下列表格所示：

-   **Hadoop**

    |Filename|classification|
    |:-------|:-------------|
    |core-site.xml|core-site|
    |log4j.properties|hadoop-log4j|
    |hdfs-site.xml|hdfs-site|
    |mapred-site.xml|mapred-site|
    |yarn-site.xml|yarn-site|
    |httpsfs-site.xml|httpsfs-site|
    |capacity-scheduler.xml|capacity-scheduler|
    |hadoop-env.sh|hadoop-env|
    |httpfs-env.sh|httpfs-env|
    |mapred-env.sh|mapred-env|
    |yarn-env.sh|yarn-env|

-   **Pig**

    |Filename|classification|
    |:-------|:-------------|
    |pig.properties|pig|
    |log4j.properties|pig-log4j|

-   **Hive**

    |Filename|classification|
    |:-------|:-------------|
    |hive-env.sh|hive-env|
    |hive-site.xml|hive-site|
    |hive-exec-log4j.properties|hive-exec-log4j|
    |hive-log4j.properties|hive-log4j|


core-site 这类扁平的 xml 文件只有一层，配置都放在 properties 里。而 hadoop-en v这类 sh 文件可能有两层结构，可以通过嵌套 configurations 的方式来设置，请参见示例里 hadoop-env 的部分，为 export 的 HADOOP\_CLIENT\_OPTS 属性添加了 -Xmx512m -Xms512m 的设置。

设置好后，确认后单击**下一步**。

