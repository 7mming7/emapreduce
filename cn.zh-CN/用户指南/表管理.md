# 表管理 {#concept_ukp_lxk_z2b .concept}

## 介绍 {#section_fkz_hyk_z2b .section}

从EMR-2.4.0版本开始，EMR支持了统一元数据管理，在EMR-2.4.0版本之前，用户所有集群均采用的是集群本地的mysql数据库作为hive元数据库，在EMR-2.4.0版本以及之后的版本中，EMR会支持统一的高可靠的hive元数据库。

![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17932/153690747811067_zh-CN.png)

用户可以选择在创建集群的时候，打开我们的元数据库的开关，从而使用外部的元数据库。

**说明：** 

-   当前元数据库需要使用公网IP来连接，所以集群必须要有公网IP，同时请不要随意的切换公网IP地址，防止对应的数据库白名单失效。
-   只有在创建集群的时候打开了统一元数据库这个开关才能使用表管理的功能，如果是本地的元数据库，目前还不支持进行管理。可以使用集群上的 Hue 工具来进行管理。

有了统一的元数据管理之后，就可以实现：

1.  提供持久化的元数据存储

    之前元数据都是在集群内部的Mysql数据库，元数据会随着集群的释放而丢失，特别是EMR提供了灵活按量模式，集群可以按需创建用完就释放。如果用户需要保留现有的元数据信息，必须登录上集群手动将元数据信息导出。支持统一的元数据管理之后，不再存在该问题。

2.  能更方便地实现计算存储分离

    EMR上可以支持将数据存放在阿里云OSS中，在大数据量的情况下将数据存储在OSS上会大大降低使用的成本，EMR集群主要用来作为计算资源，在计算完成之后机器可以随时释放，数据在OSS上，同时也不用再考虑元数据迁移的问题。

3.  更方便地实现数据共享

    使用统一的元数据库，如果用户的所有数据都存放在OSS之上，则不需要做任何元数据的迁移和重建所有集群都是可以直接访问数据，这样每个EMR集群可以做不同的业务，但是可以很方便地实现数据的共享。


**说明：** 

在支持统一元数据之前，元数据是存储在每个集群本地环境的Mysql数据库中，所以元数据会随着集群的释放消亡。在支持统一元数据之后，释放集群不会清理元数据信息。所以，在任何时候删除OSS上的数据或者集群HDFS上的数据（包括释放集群操作）的时候，需要先确认该数据对应的元数据已经删除（即要drop掉数据对应的表和数据库）。否则元数据库中可能出现一些脏的元数据信息。

## 表管理操作 {#section_izq_41l_z2b .section}

在EMR集群支持统一元数据支持之前，客户对集群上表的查看、增删操作必须要登录到集群内部环境操作，如果有多个集群，则需要每个集群上分别操作，非常不方便。在EMR支持统一元数据管理之后，为了用户更方便地对表进行管理，EMR在控制台上提供了表管理功能。包括对对数据库和表列表的查看、表详情的查看、新建数据库和表、删除数据库和表、数据预览等操作。

-   数据库和表列表

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17932/153690747811078_zh-CN.png)

-   表详情

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17932/153690747811079_zh-CN.png)

-   数据预览

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17932/153690747811080_zh-CN.png)

-   创建数据库

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17932/153690747811083_zh-CN.png)

-   创建表

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17932/153690747811085_zh-CN.png)

    创建表的时候，有两种选项：手动创建表和从文件创建表

    -   手动创建表，表示还没有对应的业务数据，手动输入表结构建一个空的表；
    -   从文件创建表，是指在已经有业务数据的情况下，可以直接将这些业务数据作为一个表，表接口是从文件内容中解析的。注意创建表时候设置的分隔符需要跟数据文件中的分隔符对应以保证表结构正确。
    分隔符不仅支持普通的逗号、空格等字符，还支持了四种特殊字符：TAB、^A、^B和^C。

    **说明：** 

    1.  如果没有任何EMR集群，不支持进行对数据库和表的创建和删除操作。
    2.  由于HDFS是每个集群内部文件系统，在没有进行特殊的网络环境设置的情况下，不同集群之间的HDFS不无法相互访问的，所以EMR表管理功能对数据库和表的创建只支持基于OSS文件系统的。
    3.  数据库和表的location都不能选择整个OSS bucket，需要选择到OSS bucket下面的目录。

## 常见问题 {#section_jkt_hdl_z2b .section}

1.  Wrong FS: oss://yourbucket/xxx/xxx/xxx

    出现这个问题，是由于删除OSS上的表数据之前，没有删除数据表对应的元数据。导致表的schema还在，但实际的数据已不存在或已移动到别的路径。可以先修改表的location为一个存在的路径，然后再删除表。

    `alter table test set location 'oss://your_bucket/your_folder'`

    可以直接在EMR控制台的交互式控制台中完成：

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17932/153690747911091_zh-CN.png)

    **说明：** oss://your\_bucket/your\_folder必须是一个存在的oss路径。

2.  Wrong FS: hdfs://yourhost:9000/xxx/xxx/xxx

    出现这个问题是删除了表在HDFS上的数据，但是没有删除表对应的schema信息，解决方法同上。

3.  删除hive database的时候出现：java.lang.IllegalArgumentException: java.net.UnknownHostException: xxxxxxx

    出现该问题的原因，是因为在之前的集群之上创建了hive的数据库，并且数据库的位置是落在之前集群的hdfs之上，但是在集群释放的时候，没有清理掉对应的hive database，导致新建集群之后，没法访问到之前已经释放集群的hdfs数据。所以如果是手动创建了在hdfs之上的数据库和表，在释放集群的时候请记得清理。

    解决方案：

    首先，通过命令行登录到集群master节点上，找到hive meta db的访问地址和用户名密码信息，在$HIVE\_CONF\_DIR/hive-site.xml中，找到对应属性。

    ```
    javax.jdo.option.ConnectionUserName //对应数据库用户名;
    javax.jdo.option.ConnectionPassword //对应数据库访问密码;
    javax.jdo.option.ConnectionURL //对应数据库访问地址和库名;
    ```

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17932/153690747911097_zh-CN.png)

    在集群master节点上登录hive meta db:

    ```
    mysql -h ${DBConnectionURL} -u ${ConnectionUserName} -p [回车]
    [输入密码]${ConnectionPassword}
    ```

    登录上hive meta db之后，修改对应hive database的location为该region真实存在的oss路径即可：

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17932/153690747911102_zh-CN.png)

4.  统一元数据库迁移到rds

    1.  购买rds实例，保证rds可以和集群的master节点网络是通的；最好是跟EMR的ecs在同一个安全组，这样可以直接使用rds的内网地址;
    2.  出于安全考虑，对rds的ip白名单进行设置，设置只允许对应的EMR机器可以访问;
    3.  在rds中创建一个database，名称为hivemeta，同时创建一个用户，把hivemeta的读写权限赋给这个用户;
    4.  登陆到EMR集群的master节点，将master中配置的mysql中的hive元数据库的数据导出来（只导出数据，不用导表结构），信息位置（3.2以及2.7以上版本可以在配置管理中找到，以下的可以在$HIVE\_CONF\_DIR/hive-site.xml 下找到）:

        ```
        javax.jdo.option.ConnectionUserName //对应数据库用户名;
        javax.jdo.option.ConnectionPassword //对应数据库访问密码;
        javax.jdo.option.ConnectionURL //对应数据库访问地址和库名;
        ```

    mysqldump　-t　hivemeta -h <数据库地址\>　-u <数据库用户名\>　-p　\>　/tmp/metastore.sql密码就是上面提到的配置中的密码。

    为了保证数据的一致性，在执行这一步操作之前，最好将hive的metastore服务停掉，保证导出期间不会有新的meta数据变化。

5.  修改集群master节点（如果是ha集群两个master都需要）上的/usr/local/emr/emr-agent/run/meta\_db\_info.json，把里面的use\_local\_meta\_db设置为false，meta数据库信的链接地址、用户名和密码换成rds的信息。
6.  在EMR控制台页面，进入“配置管理”页面，修改hive的配置，把meta数据库信的链接地址、用户名和密码换成rds的信息；如果是老版本的集群就修改 $HIVE\_CONF\_DIR/hive-site.xml 中的对应的配置为需要连接的数据库。
7.  在一台master节点上，把hive-site.xml里面的meta数据库链接地址、用户名和密码换成rds的信息，然后执行init schema:

    ```
    cd /usr/lib/hive-current/bin
    ./schematool - initSchema -dbType mysql
    ```

8.  把之前导出来的meta数据导入rds：命令行登陆mysqlmysql -h \{rds的url\} -u \{rds的用户名\} -p进入mysql的命令行之后，执行source /tmp/metastore.sql正常情况可以完全导入进去不会报错。
9.  在EMR控制台页面，“配置管理”页面，重启hive所有组件，“RESTART ALL COMPONENTS”。
10. 验证hive功能是否正常，可以在master节点上，执行hive cli，看看数据是不是跟之前一样的。

