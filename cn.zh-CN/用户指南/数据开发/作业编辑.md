# 作业编辑 {#concept_iny_t1f_z2b .concept}

在项目中，您可以创建 Shell、Hive、Spark、SparkSQL、MapReduce、Sqoop、Pig 、Spark Streaming 等类型的作业。

## 新建作业 {#section_ibf_v1f_z2b .section}

1.  通过主账号登录[阿里云 E-MapReduce 控制台](https://emr.console.aliyun.com/console)。
2.  单击上方的数据开发页签，进入项目列表页面。
3.  单击项目右侧的**工作流设计**，单击左侧导航栏中的**作业编辑**进入作业编辑页面。
4.  在页面左侧，在需要操作的文件夹上单击右键，选择**新建作业**。
5.  在**新建作业**对话框中，输入作业名称、作业描述，选择作业类型。

    创建作业时作业类型一经确定，不能修改。

6.  单击**确定**。

    **说明：** 您还可以通过在文件夹上单击右键，进行创建子文件夹、重命名文件夹和删除文件夹操作。


## 开发作业 {#section_zgm_x1f_z2b .section}

关于各类作业的具体开发，请参见 *EMR 用户指南*的[作业](cn.zh-CN/用户指南/数据开发/作业/Hadoop MapReduce 作业配置.md#)部分。

**说明：** 插入 OSS 路径时，如果选择 OSSREF 文件前缀，系统会把 OSS 文件下载到集群本地，并添加到 classpath 中。

-   作业基础设置

    单击页面右上角的**作业设置**，弹出作业设置页面。

    -   失败重试次数：设置在工作流运行到该作业失败时，重试的次数。直接在作业编辑页面运行作业，该选项不会生效。
    -   失败策略：设置在工作流运行到该作业失败时，继续执行下一个节点还是暂停当前工作流。
    -   添加运行资源：如添加作业执行需依赖的 jar 包或UDF等资源，需将资源先上传至 OSS。在作页的运行资源中选中该资源后，可以直接在作业中引用该资源。
    -   配置参数：指定作业代码中所引用变量的值。用户可以在代码中引用变量，格式为：$\{变量名\}。单击右侧的加号图标添加 key 和value，key 为变量名，value 为变量的值。另外，您还可以根据调度启动时间自定义时间变量， 规则如下：

        -   yyyy 表示 4 位的年份。
        -   MM 表示月份。
        -   dd 表示天。
        -   HH 表示 24 小时制，12 小时制使用 hh。
        -   mm 表示分钟。
        -   ss 表示秒。

            时间变量可以是包含 yyyy 年份的任意时间组合，同时支持用+和-方式来分别表示提前和延后。例如，变量 $\{yyyy-MM-dd\}表示当前日期，则：

            -   后 1 年的表示方式： $\{yyyy+1y\} 或者 $\{yyyy-MM-dd hh:mm:ss+1y\}。
            -   后 3 月的表示方式： $\{yyyyMM+3m\}或者 $\{hh:mm:ss yyyy-MM-dd+3m\}。
            -   前 5 天的表示方式： $\{yyyyMMdd-5d\}或者 $\{hh:mm:ss yyyy-MM-dd-5d\}。
            **说明：** 时间变量参数必须以'yyyy'开始，如$\{yyyy-MM\}。如果希望单独获取月份等特定时间区域的值，可以在作业内容中使用如下两个函数提取：

            -   parseDate\(<参数名称\>, <时间格式\>\):将给定参数转换为 Date对象。其中，参数名称为上述配置参数中设置的一个变量名，时间格式为设置该变量时所使用的时间格式。如设置一个变量 current\_time = $\{yyyyMMddHHmmss-1d\}, 则此处时间格式应设置为'yyyyMMddHHmmss';
            -   formatDate\(<Date对象\>, <时间格式\>\):将给定 Date 对象转换为给定格式的时间字符串。
            函数使用示例：

            -   获取 current\_time 变量的小时字面值：$\{formatDate\(parseDate\(current\_time, 'yyyyMMddHHmmss'\), 'HH'\)\}
            -   获取 current\_time 变量的年字面值：$\{formatDate\(parseDate\(current\_time, 'yyyyMMddHHmmss'\), 'yyyy'\)\}
-   作业高级设置

    在**作业设置**页面，单击**高级设置**页签。

    -   模式：包括 YARN 和 LOCAL 两种模式。YARN 模式下，作业通过 Launcher在 YARN 上分配资源进行提交。LOCAL 模式下，作业在分配的机器上直接运行。
    -   环境变量：添加作业执行的环境变量，也可以在作业脚本中直接 export 环境变量。

        例如您有一个 shell 类型的任务，内容是 `echo ${ENV_ABC}`您在这里设置了一个环境变量，`ENV_ABC=12345`那么，上面的 echo 命令您会得到输出结果：12345；进一步，如果您有一个shell类型的作业，内容是`java -jar abc.jar`，其中 abc.jar的内容是：

        ```
        public static void main(String[] args) {System.out.println(System.getEnv("ENV_ABC"));}
        ```

        那么您会得到结果： 12345

        这里的环境变量的设置相当于执行了这样的脚本：

        ```
        export ENV_ABC=12345
        java -jar abc.jar
        ```

    -   调度参数：设置作业运行 YARN 队列、CPU、内存和 Hadoop 用户等信息，可以不设置，作业会直接采用Hadoop集群的默认值。

## 配置说明 {#section_fgl_cxq_kgb .section}

新版作业提交支持两种模式，LOCAL 和 YARN，这里的 LOCAL 和 YARN 与 Spark 的yarn-client/yarn-cluster/local 模式没有任何关系，指的是提交作业的节点和方式。

-    LOCAL: spark-submit 这个进程在 header 节点运行，不受 YARN 监控。spark-submit比较耗内存，过多的作业会造成 header 节点资源紧张，进而导致整个集群不稳定。
-   YARN： spark-submit 这个进程在 worker 节点运行，占用 YARN 的一个 container，受 yarn 监控。可以缓解 header 节点的资源使用。

spark-submit 进程（在数据开发模块里为 LAUNHCER）是 Spark 的作业提交命令，用来提交 Spark 作业，一般占用 600MB+。

作业配置面板中的内存设置，用于设置 LAUNCHER 的内存配额。

一个完整的 Spark 作业包括：spark-submit （消耗内存：600MB） + driver（消耗内存：看具体作业， 可能是 JOB，也可能是LAUNCHER）+ executor （消耗内存：看具体作业实现， JOB）

-   如果 Spark 使用 yarn-client 模式， spark-submit + driver 是在同一个进程中（消耗内存：600MB + driver的内存消耗）。这个进程在作业提交中使用 LOCAL 模式的话，是 header 节点上的一个进程，不受 YARN 监控。如果用 YARN 模式的话，是 worker 上的一个进程，占用一个YARN container，受 YARN 监控。

-   如果 Spark 使用 YARN cluster 模式，driver 独立一个进程，占用 YARN 的一个 container，和 spark-submit 不在一个进程。


综上，LOCAL/YARN 决定 spark-submit 进程在 header 节点还是在 worker 节点，受不受 YARN 的监控。Spark 的 yarn-client/yarn-cluster 模式，决定 driver 是否和 spark-submit 一个进程。

## 作业执行 {#section_mmj_2bf_z2b .section}

作业开发和配置完成后，您可以单击右上角的**运行**按钮执行作业。

## 查看日志 {#section_ajt_2bf_z2b .section}

作业运行后，您可以在页面下方的运行记录页签中查看作业的运行日志。单击**详情**跳转到运行记录中该作业的详细日志页面，可以看到作业的提交日志、YARN Container 日志。

## 常见问题 {#section_wk5_mrh_dhb .section}

-   流式作业的日志过多，导致磁盘空间不足的问题

    Spark Streaming 等流式作业的场景，建议用户开启日志 Rolling，防止因为运行的时间过长而导致日志过大，磁盘空间不足的问题，具体开启方法如下：

    1.  在[E-MapReduce 控制台](https://emr.console.aliyun.com/)依次单击**数据开发** \> **项目ID** \> **作业编辑** \> **作业设置** \> **高级设置**。
    2.  在环境变量部分单机**+**添加环境变量：

        ```
        FLOW_ENABLE_LOG_ROLLING = true
        ```

    3.  保存，重启作业。

        **说明：** 如果已经发现作业日志过多，而又不想重启作业，可以先使用`echo > stde`的方式，将作业的日志清空。


