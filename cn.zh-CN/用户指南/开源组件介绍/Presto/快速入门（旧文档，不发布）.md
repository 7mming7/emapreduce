# 快速入门 {#concept_vpp_y22_z2b .concept}

本章将介绍Presto数据库的基本使用方法和应用开发方法，使开发者能够快速的使用Presto数据库进行应用开发。

## 系统组成 {#section_iqr_cf2_z2b .section}

Presto的系统组成如下图所示：

![Presto系统组成](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17915/155263549710899_zh-CN.png)

Presto是典型的M/S架构的系统，由一个Coordinator节点和多个Worker节点组成。Coordinator负责如下工作：

-   接收用户查询请求，解析并生成执行计划，下发Worker节点执行。
-   监控Worker节点运行状态，各个Worker节点与Coordinator节点保持心跳连接，汇报节点状态。
-   维护MetaStore数据。

Worker节点负责执行下发到任务，通过连接器读取外部存储系统到数据，进行处理，并将处理结果发送给Coordinator节点。

## 基本概念 {#section_wbc_2f2_z2b .section}

本节介绍Presto中到基本概念，以便更好到理解Presto到工作机制。

-   数据模型

    数据模型即数据的组织形式。Presto使用 Catalog、Schema 和 Table 这3层结构来管理数据。

    -   Catalog

        一个 Catalog 可以包含多个 Schema，物理上指向一个外部数据源，可以通过 Connector 访问改数据源。一次查询可以访问一个或多个 Catalog。

    -   Schema

        相当于一个数据库示例，一个 Schema 包含多张数据表。

    -   Table

        数据表，与一般意义上的数据库表相同。

    Catalog、Schema 和 Table 之间的关系如下图所示：

    ![Catalog，Schema ，Table 关系图](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17915/155263549710900_zh-CN.png)

-   Connector

    Presto通过各种 Connector 来接入多种外部数据源。Presto提供了一套标准的[SPI](https://prestodb.io/docs/current/develop/spi-overview.html)接口，用户可以使用这套接口，开发自己的 Connector，以便访问自定义的数据源。

    一个 Catalog 一般会绑定一种类型的 Connector（在 Catalog 的 Properties 文件中设置）。Presto内置了多种 Connector 实现。

-   查询相关概念

    本节主要介绍Presto查询过程中的相关概念，以便用户能够更好的理解Presto查询语句执行过程和性能调优方法。

    -   Statement

        即查询语句，表示用户通过JDBC或CLI输入对SQL语句。

    -   Query

        表示一次查询的执行过程，Presto接收到一个SQL Statement 后，在Coordinator中进行解析，生成执行计划，下发到Worker中执行。一个 Query 逻辑上由 Stage，Task，Driver，Split，Operator 和 DataSource 几个组件组成，如下所示：

        ![Query组件](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17915/155263549710901_zh-CN.png)

    -   Stage

        Presto中的一个 Query 由多个 Stage 组成，Stage 是一个逻辑概念，表示查询过程的一个阶段，包含了一个或多个执行任务（Task）。Presto采用树状结构组织 Stage，该树的Root节点为 Single Stage，该Stage会汇聚其上游Stage输出的数据，进行聚合运算，将结果直接发送给 Coordinator。该树的叶子节点为 Source Stage，该Stage从 Connector 获取数据进行处理。

    -   Task

        Task 表示一个具体的执行任务，是Presto任务调度的最小单元，执行过程中，Presto任务调度器会将这些Task调度到各个Worker上执行。一个Stage中的任务可以并行执行。两个Stage之间的任务通过 Exchange 模块传递数据。`Task`也是一个逻辑概念，包含了任务的参数和内容，实际的任务执行工作由 Driver 完成。

    -   Driver

        Driver 负责执行具体的任务工作。一个 Task 可以包含多个 Driver 实例，从而实现Task内部的并行处理。一个Driver 处理一个数据分片（Split）。一个 Driver 内部一组 Operator 组成，负责具体的数据操作，如转换、过滤等。

    -   Operator

        Operator 是最小的执行单元，负责对数据分片（Split）中的每一个 Page 进行处理，如加权、转换等，概念上与算子类似。Page 是 Operator 处理的最小数据单元，是一个列式的数据结构。一个 Page 对象由多个 Block 组成，每个 Block 代表一个字段的多行数据。一个Page最大为1MB，最多包含16\*1024行数据。

    -   Exchange

        两个 Stage 之间通过 Exchange 模块进行数据交换。实际的数据传输过程出现在两个 Task 之间。通常，下游的 Task 会通过其上的 Exchange Client 模块从其上游 Task 的 Output Buffer 中拉去数据。拉取的数据以 Split 为单位传递给 Driver 进行处理。


## 命令行工具 {#section_u2b_fg2_z2b .section}

通过SSH[登入EMR集群](cn.zh-CN/快速入门/步骤三：SSH 登录集群.md#)，执行下面对命令进入Presto控制台：

```
$ presto --server emr-header-1:9090 --catalog hive --schema default --user hadoop
```

高安全集群使用如下命令形式：

```
$ presto  --server https://emr-header-1:7778  \
          --enable-authentication \
          --krb5-config-path /etc/krb5.conf \
          --krb5-keytab-path  /etc/ecm/presto-conf/presto.keytab \
          --krb5-remote-service-name presto \
          --keystore-path /etc/ecm/presto-conf/keystore \
          --keystore-password 81ba14ce6084 \
          --catalog hive --schema default \
          --krb5-principal  presto/emr-header-1.cluster-XXXX@EMR.XXXX.COM
```

-   XXXX为集群的 ecm id，为一串数字，可以通过 cat /etc/hosts 获取。
-   81ba14ce6084 为 /etc/ecm/presto-conf/keystore 的默认密码，建议部署后替换为自己的keystore.

接下来就可已在该控制台下执行以下命令：

```
presto:default> show schemas;
    Schema
--------------------
default
hive
information_schema
tpch_100gb_orc
tpch_10gb_orc
tpch_10tb_orc
tpch_1tb_orc
(7 rows)
```

执行 presto --help 命令可以获取控制台的帮助，各个参数对解释如下所示：

```
--server <server>                       # 指定Coordinator的URI
--user <user>                           # 设置用户名
--catalog <catalog>                     # 指定默认的Catalog
--schema <schema>                       # 指定默认的Schema
--execute <execute>                     # 执行一条语句，然后退出
-f <file>, --file <file>                # 执行一个SQL文件，然后退出
--debug                                 # 显示调试信息
--client-request-timeout <timeout>      # 指定客户端超时时间，默认为2m
--enable-authentication                 # 使能客户端认证
--keystore-password <keystore password> # KeyStore密码
--keystore-path <keystore path>         # KeyStore路径
--krb5-config-path <krb5 config path>   # Kerberos配置文件路径（默认为/etc/krb5.conf）
--krb5-credential-cache-path <path>     # Kerberos凭据缓存路径
--krb5-keytab-path <krb5 keytab path>   # Kerberos Key table路径
--krb5-principal <krb5 principal>       # 要使用的Kerberos principal
--krb5-remote-service-name <name>       # 远程Kerberos节点名称
--log-levels-file <log levels>          # 调试日志配置文件路径
--output-format <output-format>         # 批量导出的数据格式，默认为 CSV
--session <session>                     # 指定回话属性，格式如下 key=value
--socks-proxy <socks-proxy>             # 设置代理服务器
--source <source>                       # 设置查询的Source
--version                               # 显示版本信息
-h, --help                              # 显示帮组信息
```

## 使用JDBC {#section_ydr_sg2_z2b .section}

Java应用可以使用Presto提供的JDBC driver连接数据库进，使用方式与一般RDBMS数据库差别不大。

-   在Maven中引入

    可以在pom文件中加入如下配置引入Presto JDBC driver：

    ```
    <dependency>
        <groupId>com.facebook.presto</groupId>
        <artifactId>presto-jdbc</artifactId>
        <version>0.187</version>
    </dependency>
    ```

-   Driver类名

    Presto JDBC driver类为`com.facebook.presto.jdbc.PrestoDriver`。

-   连接字串

    可以使用如下格式的连接字串：

    ```
    jdbc:presto://<COORDINATOR>:<PORT>/[CATALOG]/[SCHEMA]
    ```

    例如：

    ```
    jdbc:presto://emr-header-1:9090               # 连接数据库，使用默认的Catalog和Schema
    jdbc:presto://emr-header-1:9090/hive          # 连接数据库，使用Catalog(hive)和默认的Schema
    jdbc:presto://emr-header-1:9090/hive/default  # 连接数据库，使用Catalog(hive)和Schema(default)
    ```

-   连接参数

    Presto JDBC driver支持很多参数，这些参数既可以通过 Properties 对象传入，也可以通过URL参数传入，这两种方式是等价的。

    通过 Properties 对象传入示例：

    ```
    String url = "jdbc:presto://emr-header-1:9090/hive/default";
    Properties properties = new Properties();
    properties.setProperty("user", "hadoop");
    Connection connection = DriverManager.getConnection(url, properties);
    ......
    ```

    通过URL参数传入示例：

    ```
    String url = "jdbc:presto://emr-header-1:9090/hive/default?user=hadoop";
    Connection connection = DriverManager.getConnection(url);
    ......
    ```

    下面对各个参数进行说明：

    |参数名称|格式|参数说明|
    |:---|:-|:---|
    |user|STRING|用户名|
    |password|STRING|密码|
    |socksProxy|\\:\\|SOCKS代理服务器地址，如localhost:1080|
    |httpProxy|\\:\\|HTTP代理服务器地址，如localhost:8888|
    |SSL|true\\|是否使用HTTPS连接，默认为 false|
    |SSLTrustStorePath|STRING|Java TrustStore文件路径|
    |SSLTrustStorePassword|STRING|Java TrustStore密码|
    |KerberosRemoteServiceName|STRING|Kerberos服务名称|
    |KerberosPrincipal|STRING|Kerberos principal|
    |KerberosUseCanonicalHostname|true\\|是否使用规范化主机名，默认为 false|
    |KerberosConfigPath|STRING|Kerberos配置文件路径|
    |KerberosKeytabPath|STRING|Kerberos KeyTab文件路径|
    |KerberosCredentialCachePath|STRING|Kerberos credential缓存路径|

-   Java示例

    下面给出一个Java使用Presto JDBC driver的例子。

    ```
    .....
    // 加载JDBC Driver类
    try {
        Class.forName("com.facebook.presto.jdbc.PrestoDriver");
    } catch(ClassNotFoundException e) {
        LOG.ERROR("Failed to load presto jdbc driver.", e);
        System.exit(-1);
    }
    Connection connection = null;
    Statement statement = null;
    try {
        String url = "jdbc:presto://emr-header-1:9090/hive/default";
        Properties properties = new Properties();
        properties.setProperty("user", "hadoop");
        // 创建连接对象
        connection = DriverManager.getConnection(url, properties);
        // 创建Statement对象
        statement = connection.createStatement();
        // 执行查询
        ResultSet rs = statement.executeQuery("select * from t1");
        // 获取结果
        int columnNum = rs.getMetaData().getColumnCount();
        int rowIndex = 0;
        while (rs.next()) {
            rowIndex++;
            for(int i = 1; i <= columnNum; i++) {
                System.out.println("Row " + rowIndex + ", Column " + i + ": " + rs.getInt(i));
            }
        }
    } catch(SQLException e) {
        LOG.ERROR("Exception thrown.", e);
    } finally {
      // 销毁Statement对象
      if (statement != null) {
          try {
            statement.close();
        } catch(Throwable t) {
            // No-ops
        }
      }
      // 关闭连接
      if (connection != null) {
          try {
            connection.close();
        } catch(Throwable t) {
            // No-ops
        }
      }
    }
    ```


