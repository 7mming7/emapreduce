# 数据格式描述文件 {#concept_hw3_drd_z2b .concept}

本小节简要介绍一下索引数据的描述文件——Ingestion Spec文件，更为详细的信息请参考Druid官方文档。

Ingestion Spec（数据格式描述）是Druid对要索引数据的格式以及如何索引该数据格式的一个统一描述，它是一个JSON文件，一般由三部分组成：

```
{
    "dataSchema" : {...},
    "ioConfig" : {...},
    "tuningConfig" : {...}
}
```

|键|格式|描述|是否必须|
|:-|:-|:-|:---|
|dataSchema|JSON 对象|描述所要消费数据的schema信息。dataSchema是固定的，不随数据消费方式改变|是|
|ioConfig|JSON 对象|描述所要消费数据的来源和消费去向。数据消费方式不同，ioConfig也不相同|是|
|tuningConfig|JSON 对象|调节数据消费时的一些参数。数据消费方式不同，可调节的参数也不相同|否|

## DataSchema {#section_vqj_jrd_z2b .section}

第一部分的dataSchema描述了数据的格式，如何解析该数据，典型结构如下：

```
{
    "dataSrouce": <name_of_dataSource>,
    "parser": {
        "type": <>,
        "parseSpec": {
            "format": <>,
            "timestampSpec": {},
            "dimensionsSpec": {}
        }
    },
    "metricsSpec": {},
    "granularitySpec": {}
}
```

|键|格式|描述|是否必须|
|:-|:-|:-|:---|
|dataSource|字符串|数据源的名称|是|
|parser|JSON 对象|数据的解析方式|是|
|metricsSpec|JSON 对象数组|聚合器（aggregator）列表|是|
|granularitySpec|JSON 对象|数据聚合设置，如创建segments，聚合粒度等等|是|

-   **parser**

    parser部分决定了您的数据如何被正确地解析，metricsSpec定义了数据如何被聚集计算，granularitySpec定义了数据分片的粒度、查询的粒度。

    对于parser，type有两个选项：string和hadoopString，后者用于Hadoop索引的job。parseSpec是数据格式解析的具体定义。

    |键|格式|描述|是否必须|
    |:-|:-|:-|:---|
    |type|字符串|数据格式，可以是 “json”, “jsonLowercase”, “csv”, “tsv” 几种格式|是|
    |timestampSpec|JSON 对象|时间戳和时间戳类型|是|
    |dimensionsSpec|JSON 对象|数据的维度（包含哪些列）|是|

    对于不同的数据格式，可能还有额外的 parseSpec 选项。下面的表是 timestampSpec 和 dimensionsSpec 的描述：

    |键|格式|描述|是否必须|
    |:-|:-|:-|:---|
    |column|字符串|时间戳对应的列|是|
    |format|字符串|时间戳类型，可选”iso”, “millis”, “posix”, “auto” 和 [joda time](http://joda-time.sourceforge.net/apidocs/org/joda/time/format/DateTimeFormat.html) 支持的类型|是|

    |键|格式|描述|是否必须|
    |:-|:-|:-|:---|
    |dimensions|JSON 数组|描述数据包含哪些维度。每个维度可以只是个字符串，或者可以额外指明维度的属性，比如 “dimensions”: \[ “dimenssion1”, “dimenssion2”, “\{“type”: “long”, “name”: “dimenssion3”\} \]，默认是 string类型。|是|
    |dimensionExclusions|JSON 字符串数组|数据消费时要剔除的维度|否|
    |spatialDimensions|JSON 对象数组|空间维度|否|

-   **metricsSpec**

    metricsSpec是一个JSON对象数组，定义了一些聚合器（aggregators）。聚合器通常有如下的结构：

    ```
    ```json
    {
        "type": <type>,
        "name": <output_name>,
        "fieldName": <metric_name>
    }
    ```
    ```

    官方提供了以下常用的聚合器：

    |类型|type 可选|
    |:-|:------|
    |count|count|
    |sum|longSum, doubleSum, floatSum|
    |min/max|longMin/longMax, doubleMin/doubleMax, floatMin/floatMax|
    |first/last|longFirst/longLast, doubleFirst/doubleLast, floatFirst/floatLast|
    |javascript|javascript|
    |cardinality|cardinality|
    |hyperUnique|hyperUnique|

    **说明：** 后三个属于高级聚合器，您需要参考 [Druid 官方文档](http://druid.io/docs/0.11.0/querying/aggregations.html)学习如何使用它们。

-   **granularitySpec**

    聚合支持两种聚合方式：uniform和 arbitrary，前者以一个固定的时间间隔聚合数据，后者尽量保证每个segments大小一致，时间间隔是不固定的。目前uniform是默认选项。

    |键|格式|描述|是否必须|
    |:-|:-|:-|:---|
    |segmentGranularity|字符串|segments 粒度。uniform方式使用。|否，默认是”DAY”|
    |queryGranularity|字符串|可供查询的最小数据聚合粒度|否|
    |rollup|bool值|是否聚合|否，默认值为”true”|
    |intervals|字符串|数据消费时间间隔|对于batch是，对于realtime否|


## ioConfig {#section_v53_gsd_z2b .section}

第二部分ioConfig描述了数据来源。以下是一个Hadoop索引的例子：

```
{
    "type": "hadoop",
    "inputSpec": {
        "type": "static",
        "paths": "hdfs://emr-header-1.cluster-6789:9000/druid/quickstart/wikiticker-2015-09-16-sampled.json"
    }
}
```

对于通过Tranquility处理的流式数据，这部分是不需要的。

## Tunning Config {#section_fqd_3sd_z2b .section}

Tuning Config是指一些额外的设置。比如Hadoop对批量数据创建索引，可以在这里指定一些MapReduce参数。Tunning Config的内容依赖于您的数据来源可能有不同的内容。详细的例子可参考本服务自带的示例文件或官方文档。

