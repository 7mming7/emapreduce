# 快速入门 {#concept_tfd_fld_z2b .concept}

E-MapReduce从EMR-3.11.0版本开始支持Druid作为E-MapReduce的一个集群类型。

将Druid作为一种单独的集群类型（而不是在Hadoop集群中增加Druid组件）主要基于几个方面的考虑：

-   Druid可以完全脱离Hadoop使用。
-   大数据量下Druid对内存要求比较高，尤其是Broker节点和Historical节点。Druid本身不受YARN管控，在多服务运行时容易发生资源争抢。
-   Hadoop作为基础设施，其规模可以比较大，而Druid集群可以比较小，两者配合起来工作灵活性更高。

## 创建Druid集群 {#section_a2v_3ld_z2b .section}

在创建集群时选择Druid集群类型即可。您在创建Druid集群时可以勾选HDFS和YARN，Druid集群自带的HDFS和YARN仅供测试使用，原因如本文档开头所述。对于生产环境，我们强烈建议您采用专门的Hadoop集群。

## 配置集群 {#section_ngn_jld_z2b .section}

-   **配置使用HDFS作为Druid的deep storage**

    对于独立的Druid集群，您可能需要将您的索引数据存放在另外一个Hadoop集群的HDFS之上。为此，您需要首先设置一下两个集群的连通性（见下文[与Hadoop集群交互](#)一节），再在Druid的配置页面配置如下两个选项并重启服务即可（配置项位于配置页面的 common.runtime）。

    -   druid.storage.type: hdfs
    -   druid.storage.storageDirectory: （请注意这里HDFS 目录最好写完整目录，比如 hdfs://emr-header-1.cluster-xxxxxxxx:9000/druid/segments）
    **说明：** 如果Hadoop集群为HA集群，emr-header-1.cluster-xxxxx:9000 需要改成 emr-cluster，或者把端口9000改成8020，下同。

-   **配置使用OSS作为Druid的deep storage**

    EMR Druid支持以OSS作为deep storage，借助于EMR的免AccessKey能力，Druid不用做AccessKey配置即可访问OSS。由于OSS的访问能力是借助于HDFS的OSS功能实现的，因此在配置时，druid.storage.type 需要仍然配置为HDFS。

    -   druid.storage.type: hdfs
    -   druid.storage.storageDirectory: （如 oss://emr-druid-cn-hangzhou/segments）
    由于OSS访问借助了HDFS，因此您需要选择以下两种方案之一：

    -   建集群的时候选择安装HDFS，系统自动配好（安装好HDFS您可以不使用它，关闭它，或者仅作为测试用途）。
    -   在Druid的配置目录/etc/ecm/druid-conf/druid/\_common/下新建hdfs-site.xml，内容如下，然后将该文件拷贝至所有节点的相同目录下。

        ```
        <?xml version="1.0"?>
          <configuration>
            <property>
              <name>fs.oss.impl</name>
              <value>com.aliyun.fs.oss.nat.NativeOssFileSystem</value>
            </property>
            <property>
              <name>fs.oss.buffer.dirs</name>
              <value>file:///mnt/disk1/data,...</value>
            </property>
            <property>
              <name>fs.oss.impl.disable.cache</name>
              <value>true</value>
            </property>
          </configuration>
        ```

        其中fs.oss.buffer.dirs可以设置多个路径。

-   **配置使用RDS作为Druid的元数据存储**

    默认情况下Druid利用header-1节点上的本地MySQL数据库作为元数据存储。您也可以配置使用阿里云RDS作为元数据存储。

    下面以RDS MySQL版作为例演示配置。在具体配置之前，请先确保：

    -   RDS MySQL实例已经被创建。
    -   为Druid访问RDS MySQL创建了单独的账户（不推荐使用root），假设账户名为 druid，密码为druidpw。
    -   为Druid元数据创建单独的MySQL数据库，假设数据库名为druiddb。
    -   确保账户druid有权限访问druiddb。
    在EMR管理控制台，进入Druid集群，单击Druid组件，选择**配置**选项卡，找到 common.runtime 配置文件。单击**自定义配置**，添加如下三个配置项：

    -   druid.metadata.storage.connector.connectURI，值为 jdbc:mysql://rm-xxxxx.mysql.rds.aliyuncs.com:3306/druiddb。
    -   druid.metadata.storage.connector.user，值为druid。
    -   druid.metadata.storage.connector.password，值为druidpw。
    依次点击右上角的**保存**、**部署配置文件到主机**、**重启所有组件**，配置即可生效。

    登录RDS控制台查看druiddb创建表的情况，如果正常，您将会看到一些druid自动创建的表。

-   **组件内存配置**

    Druid组件内存设置主要包括两方面：堆内存（通过jvm.config 配置）和direct内存（通过jvm.config 和runtime.properteis配置）。在创建集群时，EMR会自动生成一套配置，不过在某些情况下您仍然可能需要自己调整内存配置。

    要调整组件内存配置，您可以通过EMR控制台进入到集群组件，在页面上进行操作。

    **说明：** 对于direct内存，调整时请确保：

    ```
    -XX:MaxDirectMemorySize >= druid.processing.buffer.sizeBytes * (druid.processing.numMergeBuffers + druid.processing.numThreads + 1)
    ```


## 批量索引 {#section_wdw_2md_z2b .section}

-   **与 Hadoop 集群交互**

    您在创建Druid集群时如果勾选了HDFS和YARN（自带 Hadoop 集群），那么系统将会自动为您配置好与HDFS和YARN的交互，您无需做额外操作。下面的介绍是配置独立Druid集群与独立Hadoop集群之间交互，这里假设Druid集群cluster id为1234，Hadoop 集群cluster id 为5678。另外请仔细阅读并严格按照指导进行操作，如果操作不当，集群可能就不会按照预期工作。

    对于与非安全独立Hadoop集群交互，请按照如下操作进行：

    1.  确保集群间能够通信（两个集群在一个安全组下，或两个集群在不同安全组，但两个安全组之间配置了访问规则）。
    2.  将Hadoop集群/etc/ecm/hadoop-conf的 core-site.xml、hdfs-site.xml、yarn-site.xml、 mapred-site.xml 放在Druid集群每个节点的 /etc/ecm/duird-conf/druid/\_common 目录下（如果创建集群时选了自带Hadoop，在该目录下会有几个软链接指向自带 Hadoop 的配置，请先移除这些软链接）。
    3.  将Hadoop集群的hosts写入到Druid集群的hosts列表中，注意Hadoop集群的 hostname 应采用长名形式，如 emr-header-1.cluster-xxxxxxxx，且最好将Hadoop的hosts放在本集群hosts之后，例如：

        ```
        ...
        10.157.201.36   emr-as.cn-hangzhou.aliyuncs.com
        10.157.64.5     eas.cn-hangzhou.emr.aliyuncs.com
        192.168.142.255 emr-worker-1.cluster-1234 emr-worker-1 emr-header-2.cluster-1234 emr-header-2 iZbp1h9g7boqo9x23qbifiZ
        192.168.143.0   emr-worker-2.cluster-1234 emr-worker-2 emr-header-3.cluster-1234 emr-header-3 iZbp1eaa5819tkjx55yr9xZ
        192.168.142.254 emr-header-1.cluster-1234 emr-header-1 iZbp1e3zwuvnmakmsjer2uZ
        --以下为hadoop集群的hosts信息
        192.168.143.6   emr-worker-1.cluster-5678 emr-worker-1 emr-header-2.cluster-5678 emr-header-2 iZbp195rj7zvx8qar4f6b0Z
        192.168.143.7   emr-worker-2.cluster-5678 emr-worker-2 emr-header-3.cluster-5678 emr-header-3 iZbp15vy2rsxoegki4qhdpZ
        192.168.143.5   emr-header-1.cluster-5678 emr-header-1 iZbp10tx4egw3wfnh5oii1Z
        ```

    对于安全Hadoop集群，请按如下操作进行：

    1.  确保集群间能够通信（两个集群在一个安全组下，或两个集群在不同安全组，但两个安全组之间配置了访问规则）。
    2.  将Hadoop集群 /etc/ecm/hadoop-conf 的 core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml放在Druid集群每个节点的 /etc/ecm/duird-conf/druid/\_common 目录下（如果创建集群时选了自带Hadoop，在该目录下会有几个软链接指向自带Hadoop的配置，请先移除这些软链接），并修改 core-site.xml 中 hadoop.security.authentication.use.has 为 false（这是一条客户端配置，目的是让用户能够使用AccessKey认证，如果用Kerberos认证方式，需disable该配置）。
    3.  将Hadoop集群的hosts写入到Druid集群每个节点的hosts列表中，注意Hadoop集群的hostname应采用长名形式，如 emr-header-1.cluster-xxxxxxxx，且最好将hadoop的 hosts放在本集群hosts之后。
    4.  设置两个集群间的Kerberos跨域互信（详情参考[跨域互信](intl.zh-CN/用户指南/Kerberos认证/跨域互信.md#)）。
    5.  在Hadoop集群的所有节点下都创建一个本地Druid账户（useradd -m -g hadoop druid），或者设置 druid.auth.authenticator.kerberos.authToLocal（具体预发规则参考[这里](http://druid.io/docs/0.11.0/development/extensions-core/druid-kerberos.html)）创建Kerberos账户到本地账户的映射规则。推荐第一种做法，操作简便不易出错。

        **说明：** 默认在安全Hadoop集群中，所有Hadoop命令必须运行在一个本地的账户中，该本地账户需要与principal的name部分同名。YARN也支持将一个principal映射至本地一个账户，即上文第二种做法。

    6.  重启Druid服务。
-   **使用Hadoop对批量数据创建索引**

    Druid自带了一个名为wikiticker的例子，位于$\{DRUID\_HOME\}/quickstart下面（$\{DRUID\_HOME\}默认为 /usr/lib/druid-current）。wikiticker文件（wikiticker-2015-09-12-sampled.json.gz）的每一行是一条记录，每条记录是个json对象。其格式如下所示：

    ```
    ```json
    {
        "time": "2015-09-12T00:46:58.771Z",
        "channel": "#en.wikipedia",
        "cityName": null,
        "comment": "added project",
        "countryIsoCode": null,
        "countryName": null,
        "isAnonymous": false,
        "isMinor": false,
        "isNew": false,
        "isRobot": false,
        "isUnpatrolled": false,
        "metroCode": null,
        "namespace": "Talk",
        "page": "Talk:Oswald Tilghman",
        "regionIsoCode": null,
        "regionName": null,
        "user": "GELongstreet",
        "delta": 36,
        "added": 36,
        "deleted": 0
    }
    ```
    ```

    使用Hadoop对批量数据创建索引，请按照如下步骤进行操作：

    1.  将该压缩文件解压，并放置于HDFS的一个目录下（如 hdfs://emr-header-1.cluster-5678:9000/druid）。 在Hadoop集群上执行如下命令。

        ```
        ### 如果是在独立Hadoop集群上进行操作，需要做好两个集群互信之后需要拷贝一个 druid.keytab到Hadoop集群再kinit。
         kinit -kt /etc/ecm/druid-conf/druid.keytab druid
         ###
         hdfs dfs -mkdir hdfs://emr-header-1.cluster-5678:9000/druid
         hdfs dfs -put ${DRUID_HOME}/quickstart/wikiticker-2015-09-16-sampled.json hdfs://emr-header-1.cluster-5678:9000/druid
        ```

        **说明：** 

        -   对于安全集群执行HDFS命令前先修改 /etc/ecm/hadoop-conf/core-site.xml 中 hadoop.security.authentication.use.has 为 false。
        -   请确保已经在Hadoop集群每个节点上创建名为druid的Linux账户。
    2.  修改Druid集群 $\{DRUID\_HOME\}/quickstart/wikiticker-index.json，如下所示：

        ```
        {
             "type" : "index_hadoop",
             "spec" : {
                 "ioConfig" : {
                     "type" : "hadoop",
                     "inputSpec" : {
                         "type" : "static",
                         "paths" : "hdfs://emr-header-1.cluster-5678:9000/druid/wikiticker-2015-09-16-sampled.json"
                     }
                 },
                 "dataSchema" : {
                     "dataSource" : "wikiticker",
                     "granularitySpec" : {
                         "type" : "uniform",
                         "segmentGranularity" : "day",
                         "queryGranularity" : "none",
                         "intervals" : ["2015-09-12/2015-09-13"]
                     },
                     "parser" : {
                         "type" : "hadoopyString",
                         "parseSpec" : {
                             "format" : "json",
                             "dimensionsSpec" : {
                                 "dimensions" : [
                                     "channel",
                                     "cityName",
                                     "comment",
                                     "countryIsoCode",
                                     "countryName",
                                     "isAnonymous",
                                     "isMinor",
                                     "isNew",
                                     "isRobot",
                                     "isUnpatrolled",
                                     "metroCode",
                                     "namespace",
                                     "page",
                                     "regionIsoCode",
                                     "regionName",
                                     "user"
                                 ]
                             },
                             "timestampSpec" : {
                                 "format" : "auto",
                                 "column" : "time"
                             }
                         }
                     },
                     "metricsSpec" : [
                         {
                             "name" : "count",
                             "type" : "count"
                         },
                         {
                             "name" : "added",
                             "type" : "longSum",
                             "fieldName" : "added"
                         },
                         {
                             "name" : "deleted",
                             "type" : "longSum",
                             "fieldName" : "deleted"
                         },
                         {
                             "name" : "delta",
                             "type" : "longSum",
                             "fieldName" : "delta"
                         },
                         {
                             "name" : "user_unique",
                             "type" : "hyperUnique",
                             "fieldName" : "user"
                         }
                     ]
                 },
                 "tuningConfig" : {
                     "type" : "hadoop",
                     "partitionsSpec" : {
                         "type" : "hashed",
                         "targetPartitionSize" : 5000000
                     },
                     "jobProperties" : {
                         "mapreduce.job.classloader": "true"
                     }
                 }
             },
             "hadoopDependencyCoordinates": ["org.apache.hadoop:hadoop-client:2.7.2"]
         }
        ```

        **说明：** 

        -   spec.ioConfig.type 设置为 hadoop。
        -   spec.ioConfig.inputSpec.paths 为输入文件路径。
        -   tuningConfig.type 为 hadoop。
        -   tuningConfig.jobProperties 设置了 mapreduce job 的 classloader。
        -   hadoopDependencyCoordinates 制定了 hadoop client 的版本。
    3.  在Druid集群上运行批量索引命令。

        ```
        cd ${DRUID_HOME}
         curl --negotiate -u:druid -b ~/cookies -c ~/cookies -XPOST -H 'Content-Type:application/json' -d @quickstart/wikiticker-index.json http://emr-header-1.cluster-1234:18090/druid/indexer/v1/task
        ```

        其中 `- -negotiate`、`-u`、`-b`、`-c` 等选项是针对安全Druid集群的。Overlord的端口默认为18090。

    4.  查看作业运行情况。

        在浏览器访问 http://emr-header-1.cluster-1234:18090/console.html 查看作业运行情况。为了能正常访问该页面，您可能需要事先开启一个SSH隧道（详见[SSH 登录集群](intl.zh-CN/用户指南/SSH 登录集群.md#)“查看 Hadoop、Spark、Ganglia 等系统的 WebUI”小节），并启动一个代理Chrome。如果Druid集群开启了高安全，您还得配置您的浏览器支持Kerberos的认证流程，可参考[这里](http://druid.io/docs/0.11.0/development/extensions-core/druid-kerberos.html)。

    5.  根据Druid语法查询数据。

        Druid有自己的查询语法。您需要准备一个描述您如何查询的json格式的查询文件，如下所示为对wikiticker数据的一个top N查询（$\{DRUID\_HOME\}/quickstart/wikiticker-top-pages.json）：

        ```
        {
             "queryType" : "topN",
             "dataSource" : "wikiticker",
             "intervals" : ["2015-09-12/2015-09-13"],
             "granularity" : "all",
             "dimension" : "page",
             "metric" : "edits",
             "threshold" : 25,
             "aggregations" : [
                 {
                     "type" : "longSum",
                     "name" : "edits",
                     "fieldName" : "count"
                 }
             ]
         }
        ```

        在命令行界面运行下面的命令即可看到查询结果：

        ```
        cd ${DRUID_HOME}
         curl --negotiate -u:druid -b ~/cookies -c ~/cookies -XPOST -H 'Content-Type:application/json' -d @quickstart/wikiticker-top-pages.json 'http://emr-header-1.cluster-1234:18082/druid/v2/?pretty'
        ```

        其中 `- -negotiate`、`-u`、`-b`、`-c` 等选项是针对安全Druid集群的。如果一切正常，您将能看到具体地查询结果。

-   **实时索引**

    我们推荐使用[Tranquility 客户端](https://github.com/druid-io/tranquility)向Druid发送实时数据。Tranquility支持Kafka、Flink、Storm、Spark Streaming等多种方式向Druid发送数据。对于Kafka方式，可参考[Tranquility](intl.zh-CN/用户指南/开源组件介绍/Druid使用说明/Tranquility.md#)中Druid使用Tranquility Kafka一节。更多的使用方式以及SDK的使用方法，可参考[Tranquility帮助文档](https://github.com/druid-io/tranquility/tree/master/docs)。

    对于Kafka方式，您还可以使用kafka-indexing-service扩展，详见[Kafka Indexing Service](intl.zh-CN/用户指南/开源组件介绍/Druid使用说明/Kafka Indexing Service.md#)中“使用Druid Kafka Indexing Service实时消费Kafka数据”一节。

-   **索引失败问题分析思路**

    当发现索引失败时，一般遵循如下排错思路：

    -   **对于批量索引**
        1.  如果curl直接返回错误，或者不返回，检查一下输入文件格式。或者curl加上 -v 参数，观察REST API的返回情况。
        2.  在Overlord页面观察作业执行情况，如果失败，查看页面上的logs。
        3.  在很多情况下并没有生成logs，如果是Hadoop作业，打开YARN页面查看是否有索引作业生成，并查看作业执行log。
        4.  如果上述情况都没有定位到错误，需要登录到Druid集群，查看overlord的执行日志（位于/mnt/disk1/log/druid/overlord—emr-header-1.cluster-xxxx.log），如果是HA 集群，查看您提交作业的那个Overlord。
        5.  如果作业已经被提交到Middlemanager，但是从Middlemanager返回了失败，则需要从Overlord中查看作业提交到了那个worker，并登录到相应的worker，查看Middlemanager的日志（位于/mnt/disk1/log/druid/middleManager-emr-header-1.cluster-xxxx.log）。
    -   **对于Tranquility实时索引**

        查看Tranquility log，查看消息是否被接收到了或者是否被丢弃（drop）掉了。

        其余的排查步骤同批量索引的[步骤2](#)～[步骤5](#)。

        错误多数情况为集群配置问题和作业问题。集群配置问题包括：内存参数是否合理、跨集群联通性是否正确、安全集群访问是否通过、principal是否正确等等，作业问题包括作业描述文件格式正确，输入数据是否能够正常被解析，以及一些其他的作业相关的配置（如ioConfig等）。


