# 步骤三：创建并运行作业 {#concept_jkh_sb4_y2b .concept}

本节将创建并运行一个 Spark Pi 的作业示例，并最终在控制台上显示圆周率 Pi 的近似计算结果，以帮助您快速了解 E-MapReduce 中集群、作业的作用和使用方法。

## 前提条件 {#section_ztd_t2v_vgb .section}

请确认您已经完成了必选的[准备工作](cn.zh-CN/快速入门/步骤一：准备工作.md#)。

## 操作步骤 {#section_ujn_w2v_vgb .section}

1.  创建集群
    1.  在[阿里云 E-MapReduce 控制台](https://emr.console.aliyun.com/)单击上方的集群管理页签，进入集群列表页面，并单击右上**创建集群**。
    2.  软件配置
        1.  选择最新的 EMR 产品版本，例如 **EMR-x.x.x**。
        2.  使用默认软件配置。
    3.  硬件配置
        1.  选择**按量付费**。
        2.  若没有安全组，请输入新的安全组名称新建。
        3.  Master 配置选择 4 核 8 G。
        4.  Core 配置选择 4 核 8 G， 两台。
        5.  其他保持默认。
    4.  基础配置
        1.  填写集群名称。
        2.  选择日志路径保存作业日志，请务必开启运行日志服务。在集群对应的地域，[创建 OSS 的 Bucket](../../../../cn.zh-CN/快速入门/创建存储空间.md#)。
        3.  填写密码。
    5.  检查**配置清单**无误后，单击**确认**。
2.  创建作业
    1.  单击上方的数据开发页签，进入项目列表页面，并单击右上**新建项目**。
    2.  在新建项目对话框输入项目名称和项目描述，单击**创建**。
    3.  单击对应项目右侧的**工作流设计**，单击左侧**作业编辑**进入**作业编辑**页面。
    4.  在页面左侧，在需要操作的文件夹上单击右键，选择**新建作业**。
    5.  填写作业名称和作业描述。
    6.  选择 Spark 类型。
    7.  单击**确定**。

        **说明：** 您还可以通过在文件夹上单击右键，进行创建子文件夹、重命名文件夹和删除文件夹操作。

    8.  参数填写，使用如下：

        ```
        --class org.apache.spark.examples.SparkPi --master yarn-client --driver-memory 512m --num-executors 1 --executor-memory 1g --executor-cores 2 /usr/lib/spark-current/examples/jars/spark-examples_2.11-2.1.1.jar 10
        ```

        **说明：** 这个`/usr/lib/spark-current/examples/jars/spark-examples_2.11-2.1.1.jar`, 需要根据实际集群中的 Spark 版本来修改这个 jar 包，比如 Spark 是 2.1.1 的， 那么就是`spark-examples_2.11-2.1.1.jar`，如果是 2.2.0 的，那么就是`spark-examples_2.11-2.2.0.jar`。

    9.  单击**运行**。
3.  查看作业日志并确认结果。

    作业运行后，您可以在页面下方的运行记录页签中查看作业的运行日志。单击**详情**跳转到运行记录中该作业的详细日志页面，可以看到作业的提交日志、YARN Container 日志。


## OSS 与 OSSREF {#section_rjr_cx4_y2b .section}

**oss://**的前缀代表数据路径指向一个 OSS 路径，当要读写该数据的时候，这个指明了操作的路径，与**hdfs://**类似。

**ossref://** 同样是指向一个 OSS 的路径，不同的是它会将对应的代码资源下载到本地，然后将命令行中的路径替换为本地路径。它是用于更方便地运行一些本地代码，而不需要登录到机器上去上传代码和依赖的资源包。

上面的例子中， **ossref://xxxxxx/xxx.jar** 这个参数代表作业资源的jar，这个jar存放在 OSS 上，在运行的时候，E-MapReduce 会自动下载到集群中运行。而跟在 jar 后面的 2 个 **oss://xxxx** 以及另外两个值则是作为参数出现，他们会被作为参数传递给 jar 中的主类来处理。

**说明：** **ossref**不可以用来下载过大的数据资源，否则会导致集群作业的失败。

