# 步骤三：创建集群 {#concept_nrp_154_y2b .concept}

本文将介绍创建 E-MapReduce （以下简称 EMR）集群的操作步骤和相关配置。

## 前提条件 {#section_dqd_rnv_vgb .section}

请确认您已经完成了 RAM 授权，操作步骤请参见[ZH-CN\_TP\_17844\_V9.md\#](intl.zh-CN/集群规划与配置/集群规划/角色授权.md#)。

## 进入创建集群页面 {#section_w2j_2z4_y2b .section}

1.  登录[阿里云 E-MapReduce 控制台](https://emr.console.aliyun.com/)。
2.  在上方选择所在的地域（Region），所创建集群将会在对应的地域内，一旦创建后不能修改。
3.  单击**创建集群**，进行创建。

## 创建集群流程 {#section_rsk_gz4_y2b .section}

要创建集群，您需要继续完成以下三个步骤：

-   软件配置
-   硬件配置
-   基础配置

步骤1：软件配置

配置项说明：

-   **产品版本**：选择默认最新的软件版本。
-   **集群类型**：
    -   Hadoop 集群，提供半托管的 Hadoop、Hive、Spark 离线大规模分布式数据存储和计算，SparkStreaming、Flink、Storm 流式数据计算，Presto、Impala 交互式查询，Oozie、Pig 等 Hadoop 生态圈的组件，具体的组件信息可以在选择界面的列表中查看。
    -   Kafka 集群，是半托管分布式的、高吞吐量、高可扩展性的消息系统。提供一套完整的服务监控体系，保障集群稳定运行，用户无需部署运维，更专业、更可靠、更安全。广泛用于日志收集、监控数据聚合等场景，支持离线或流式数据处理、实时数据分析等。
    -   Druid 集群，提供半托管式实时交互式分析服务，大数据查询毫秒级延迟，支持多种数据摄入方式。可与 EMR Hadoop、EMR Spark、OSS、RDS 等服务搭配组合使用，构建灵活稳健的实时查询解决方案。
    -   Data Science 集群，主要面向大数据+AI场景，提供了 Hive、Spark 离线大数据 ETL，TensorFlow 模型训练，用户可以选择CPU+GPU的异构计算框架，利用英伟达 GPU 对部分深度学习算法进行高性能计算。
-   **必选服务**：默认的服务组件，后期可以在管理界面中添加和启停服务。
-   **可选服务**：根据需求，您可选择不同的组件，被选中的组件会默认启动相关的服务进程。
-   高级设置
    -   **Kerberos 集群模式**：是否开启集群的 Kerberos 认证功能。一般的个人用户集群无需该功能，默认关闭。
    -   **软件自定义配置**：可以指定一个 json 文件修改软件配置，详细使用方法请参见[软件配置](../../../../intl.zh-CN/集群规划与配置/第三方软件/软件配置.md#)。

步骤 2：硬件配置

配置项说明：

-   付费配置

    -   **付费类型**：测试的场景下使用按量开始，测试都正常了以后，可以新建一个包月的生产集群正式使用。
        -   **按量付费**
        -   **包年包月** 
            -   **付费时长**：包年包月如果购买一年则会在原价（12个月）的基础上打 85 折。
            -   **自动续费**：到期前7天执行自动续费操作，续费时长为一个月。
-   网络配置
    -   **可用区**：可用区为在同一地域下的不同物理区域，可用区之间内网互通。一般使用默认的可用区即可。
    -   **网络类型**：默认使用 VPC。若还未创建，可前往[VPC 控制台](https://vpc.console.aliyun.com/)进行创建。
    -   **VPC**：选择在该地域的 VPC。如没有，单击**创建 VPC / 子网\(交换机）**前往新建。
    -   **交换机**：选择在对应的 VPC 下的在对应可用区的交换机，如果在这个可用区没有可用的交换机，那么就需要前往去创建一个新的使用。
    -   **安全组名称**：一般用户初次来到这里还没有安全组，用户可以输入新的安全组名称新建一个安全组。若已经有在使用的安全组可以直接这里选择使用。
-   集群节点配置
    -   **高可用**：打开后，Hadoop 集群会有 2 个 master 节点来支持 ResourceManager 和 NameNode 的高可用。HBase 集群原来就支持高可用，只是另一个节点用其中一个 core 节点来充当，如果打开高可用，会独立使用一个 master 节点来支持高可用，更加的安全可靠。后续正式集群如果是使用高可用的，测试情况下也打开高可用。
    -   Master 实例：主要负责 ResourceManager，NameNode 等控制进程的部署。

        您可以根据需要选择实例规格，请参考[实例规格族](../../../../intl.zh-CN/实例/实例规格族.md#)。

        -   **系统盘配置**：根据需要选择高效或者是 SSD 云盘。
        -   **系统盘大小**： 根据需要调整磁盘容量，推荐至少 120 G。
        -   **数据盘配置**：根据需要选择高效或者是 SSD 云盘。
        -   **数据盘大小**：根据需要调整磁盘容量，推荐至少 80 G。
        -   **Master 数量**：默认 1 台。
    -   Core 实例：主要负责集群所有数据的存储，可以按照需要进行扩容。
        -   **系统盘配置**：根据需要选择高效或者是 SSD 云盘。
        -   **系统盘大小**： 根据需要调整磁盘容量，推荐至少 80 G。
        -   **数据盘配置**：根据需要选择高效或者是 SSD 云盘。
        -   **数据盘大小**：根据需要调整磁盘容量，推荐至少 80 G。
        -   **Core数量**：默认 2 台，根据需要调整。
    -   **Task 实例**：不保存数据，调整集群的计算力使用。默认关闭，需要的时候再追加。

步骤3：基础配置

配置项说明：

-   **基础信息**

    -   **集群名称**：集群的名字，长度限制为 1-64 个字符，仅可使用中文、字母、数字、中划线（-）和下划线（\_）。
    -   **远程登录**：是否打开安全组 22 端口，默认开启。
    -   **密钥对**：关于密钥对的使用，请参考 [SSH 密钥对](../../../../intl.zh-CN/安全/SSH密钥对/SSH密钥对概述.md#)。
    -   **登录密码**：设置 master 节点的登录密码。8 - 30 个字符，且必须同时包含大写字母、小写字母、数字和特殊字符 !@\#$%^&\*。
-   高级设置
    -   **统一 Meta 数据库**：Hive 使用统一的集群外部的meta数据库，集群释放后 Meta 信息仍然存在。推荐先关闭。
    -   **添加 Knox 用户**：添加用户访问开源大数据软件 Web UI 的账号。
    -   **权限设置**：通过 RAM 角色为在集群上运行的应用程序提供调用其他阿里云服务所需的必要权限。无需调整，使用默认即可。
    -   **引导操作**（可选）： 您可以在集群启动 Hadoop 前执行您自定义的脚本，详细使用说明请参见[引导操作](../../../../intl.zh-CN/集群规划与配置/第三方软件/引导操作.md#)。

## 确认创建 {#section_htk_gz4_y2b .section}

在配置清单上确认配置和对应的费用。当所有的信息都有效填写以后，**创建**按钮会亮起，确认无误后单击**创建**将会创建集群。

**说明：** 

-   若是按量付费集群，集群会立刻开始创建。页面会返回集群列表页，就能看到在**集群概览**中有一个**初始化中**的集群。请耐心等待，集群创建会需要几分钟时间。完成之后集群的状态会切换为**空闲**。
-   若是包年包月集群，则会先生成订单，在支付完成订单以后集群才会开始创建。

## 异常处理：查看集群创建失败原因 {#section_jtk_gz4_y2b .section}

如果创建失败，在集群列表页上会显示**集群创建失败**，将鼠标移动到红色的感叹号上会看到失败原因，如下图所示。

 ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17840/155789986910549_zh-CN.png) 

创建失败的集群可以不用处理，对应的计算资源并没有真正的创建出来。这个集群会在停留 3 天以后自动隐藏。

